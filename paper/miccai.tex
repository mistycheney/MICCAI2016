\documentclass{llncs}

\usepackage{makeidx}  % allows for indexgeneration

\usepackage{graphics, graphicx, xcolor}
\usepackage{amsmath}
%\usepackage[square]{natbib}
\usepackage{cite}
\usepackage[hidelinks, colorlinks, linkcolor={red},citecolor={blue}, urlcolor={blue}, backref=section]{hyperref}

\usepackage{times}
\usepackage{mathptmx}
%\usepackage{newtxtext,newtxmath}

\newcommand{\authcmt}[2]{\textcolor{#1}{#2}}
\newcommand{\yuncong}[1]{\authcmt{red}{[YC: #1]}}
\newcommand{\yoav}[1]{\authcmt{blue}{[YF: #1]}}

\begin{document}

%\abovedisplayskip=2pt
%\abovedisplayshortskip=1pt
%\belowdisplayskip=2pt 
%\belowdisplayshortskip=1pt
\textfloatsep=5pt
\intextsep=3pt

%
%\mainmatter              % start of the contributions
%
\title{Building Active Atlas for Mouse Brainstem}
%
%\titlerunning{Robust Landmark Detection for Mouse Brain Images}  % abbreviated title (for running head)
%%                                     also used for the TOC unless
%%                                     \toctitle is used
%%
\author{Yuncong Chen\inst{1}, Yoav Freund\inst{1}, David Kleinfeld\inst{2}}
%
%\authorrunning{Yuncong Chen et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
% \tocauthor{Yuncong Chen, Yoav Freund}
%
\institute{UCSD Computer Science and Engineering Department
\and UCSD Physics Department}

\maketitle              % typeset the title of the contribution
\begin{abstract}

We propose a semi-supervised system for generating a reference atlas from histology image series of the mouse brainstem.
The atlas contains the mean and variance of the positions and shapes of nine anatomical landmarks. By learning landmark classifiers, the system registers new data to the atlas. Registered data further improve the generalizability of the classifiers.

\keywords{landmark detection, atlas generation, mouse brain, registration, automated annotation}

\end{abstract}

\section{Overview}

\yuncong{Putting MRI at the very first word of the paper makes me feel this paper is about MRI. Also we are not really comparing against MRI, the related work we compare to mostly use confocal or two-photon microscopy, which produce volumetric images. The advantage of MRI is the preservation of a realistic 3D volume, which can be obtained by confocal / two-photon microscopy as well and at a much higher resolution. So I think unless we compare with these techniques, we better not do it. What we can discuss as a motivation is why some neuroscientists prefer to actually cut and image the sections, instead of imaging the whole volume using optical sectioning. In fact, Allen did use serial two-photon microscopy stacks for their connectivity atlas work. So I guess tissue thickness is not the reason? Maybe David can answer this.. }

MRI has gained great popularity in recent years, however, the
limitations of MRI in terms of resolution and variety of markers
(stains) means that light microscopy is still a method of great
importance.  One of the most important tools when analyzing light
microscopy brain section is the brain atlas. Over time Atlases have
improved in accuracy and coverage: Starting with Paxinos, and the
Waxholm Space \cite{johnson2010waxholm}, and continuing with the Allen
Reference Atlas \cite{dong2008allen} and its successors.

An atlas is a visual reference: the researcher compares the
images in the atlas to new section images in order to orient herself
and to find the loci of interest. This is a time consuming
process. The fact that the researcher is interested only in a specific
set of loci means that other parts of the brain will not be
identified. 

We propose a new type of atlas which we call the ``active
atlas''. Unlike ``static atlases'', which are used as
visual reference, the active atlas is a computer program that takes a
section stack as input and then overlays a standard brain coordinate
system (the Waxholm space coordinates) on the sections.

\yuncong{I do not have results for a standard coordinate system yet. Harvey was suggesting to use the stereotactic coordinate system in Paxinos. And in the future, align the stereotactic system to Walxhom space as well as Allen Reference Brain's coordinate system. I have not done these yet. Do you think I should at least specify a stereotactic coordinate system, so that we can show images with grid lines on top of them ? }

An active atlas represents both the nominal location of the brain loci
and the variation in these locations.

An active atlas will enable automatic analysis of specific
stains (dyes?). Dyes are available that can identfy highly
specific characteristics in the brain. RNA binding markers can
identify gene activity, forward projecting and backward projecting
dyes mark the connectivity between brain regions and muscles and
between brain regions and sensors. \yoav{David please help!}

The active atlas is related to the common practice of
section-to-section registration, but is fundamentally different.
\begin{itemize}
\item Registration aligns two neighboring sections of the same brain to each other,
  while the active atlas aligns a section to a plane in the atlas.
\item Registration is intended to produce a 3D image from a single
  stack, the active atlas is intended to align multiple brains to each other.
\end{itemize}

\yuncong{These two fundamental differences simply are the differences between 2D-2D registration and 3D-3D registration. They are not unique to the ``active atlas" concept. I don't think this part is necessary. Otherwise, we should emphasize how our approach for 3D-3D registration is different from other projects, most of whom rely on intensity correlation, contour consistency, or picking 3D point rather than region landmarks.}

\noindent Some challanges on the way to producing an atlas are:
\begin{itemize}
\item Grey level information can only identify some of the landmarks
  in a typical section. Much of the area is of similar average grey
  level. Important information lies in the shapes and organization of
  the neurons.
\item When comparing the same locus in different brains, there is no
  one-to-one mapping between the neurons. The organization of the
  neurons can only be characterized using statistical properties.
\end{itemize}

\yuncong{I feel this part involves a mix of issues/claims, some of which apply to all registration method (e.g. grey-level is not enough, the need to describe texture), some of which apply to any atlas generation method (e.g. 3D-3D registration), and some of which apply only to ACTIVE atlas (still weak - what separates ``active atlas" from an ``static atlas" plus a 3D-3D registration algorithm).}



Our contribution is in developing a methodology for developing an \yuncong{active}
atlas and an alignment algorithm for matching a new stack to this
atlas. 

\yuncong{I think we should give a high-level description of our methodology here.}

The rest of the paper is organized as follow. In Section~\ref{sec:related} we
describe related work. In Section 3 we describe the semi-supervised
method we used to create landmark detectors. In section 4 we describe
the alignment algorithm and the way in which we quantify the variation
in the location of the landmarks. In section 5 we describe out
experimental result. We conclude in section 6 with lessons learned and
future plans. 

\section{Related work}
\label{sec:related}

Existing atlases of the mouse brain include Paxinos, Waxholm Space \cite{johnson2010waxholm}, and the more recent Allen Reference Atlas \cite{dong2008allen} and its successors, on top of which gene expression data \cite{lein2007genome, ng2009anatomic} as well as connectivity information \cite{oh2014mesoscale} are mapped. The latest version of their common coordinate framework \cite{ccf2015} is generated by deformably averaging two-photon microscopy images and manually demarcating structures with the help of immunohistochemistry data and genetic labeling data. Atlases for smaller organisms such as fruit flies \cite{peng2011brainaligner, chiang2011three} and zebrafish \cite{ronneberger2012vibe, randlett2015whole} are mostly based on volumetric images acquired by confocal microscopy. 
For registration, the BrainAligner program \cite{peng2011brainaligner} relies on matching high-curvature points, and the ViBE-Z project \cite{ronneberger2012vibe} used trained classifiers to detect predefined 3D landmarks. 

These atlases are not updateable from new data, and do not provide means that facilitate the registration of new data.

\yuncong{Do you think the two paragraphs below should be in the first section, since they highlight the largest feature of our system (i.e. use machine learning), and provides more reasons why it is ``active" }

This paper proposes a machine-learning based method that generates an anatomical reference model from Nissl-stained cryo-section images. 

In addition to describing the statistics of position and shape of anatomical structures, the model also include landmark detectors. These detectors are texture classifiers trained in a semi-supervised fashion to detect regions with salient texture that can serve as registration landmarks, such as nuclei and tracts. Because these detectors allows our system to actively detect landmarks on new data for registeration, instead of being a mere registration template; and also because these detectors can update themselves from new data, we refer to this system as an ``active atlas". 


\section{Methodology}


Registration to the atlas is based on landmark probability maps generated by the classifiers.


An $M$-way classifier detects landmarks on each image, assigning a probability vector to each pixel. Intra-stack registration is performed for each stack separately based on intensity. Assuming constant section thickness and the sections being parallel, a volume can be reconstructed for each stack, in which every voxel has a probability vector.

Given a stack of section images, the \textit{elastix} program \cite{klein2010elastix} is used to find rigid transformations that align every pair of consecutive sections, by maximizing the normalized correlation of image intensity. These transformations are then composed, bringing the whole stack into a rough alignment. Because the tape-transfer system used to process these sections preserves the tissues very well, 3-parameter rigid transforms are sufficient for this stage of registration.

For each image in the stack, a $M$-way classifier assigns a landmark probability vector to each pixel. The result is a set of score maps ${S_l}$, one for each landmark.

We then register the test volume to the atlas. A 3D rigid transform is seeked that maximizes the same-class overlap score between the test volume and the atlas. The score is defined as:
\[ M(T) = \sum_l \sum_{p \in V_l} S_l[T(p)]\;,\]
where $T$ is the transformation that maps voxels from the atlas to the test volume, $l$ indexes the landmark labels, $V_l$ is the set of voxels in the atlas with label $l$, $S_l$ is the score map for label $l$.

The optimal parameters are found using a coarse-to-fine grid search, followed by gradient descent that moves the solution towards the maxima.

%Three components of the system employ machine learning: landmark discovery, landmark modelling and landmark localization. 
%
%%They allow regions of interest to be detected on the images with little supervision.
%
%Landmark discovery involves finding candidate landmarks that are salient and consistent along the stack. Each landmark is modelled using their appearance features such as texture, shape and striation directions, in addition to position. On every image, the landmarks are localized based on their models. Models are also updated according to detections at the new location. In a sentence, learning in this system is a semi-supervised, interactive and iterative scheme that combines unsupervised model discovery with examples (corrections) from human experts.
%
%
%Previously we have developed a superpixel-based method that identifies salient and consistent regions and boundaries across an image stack. In that method, region growing is used to obtain a region proposal for each superpixel. These region proposals are clustered and weighted according to saliency. Salient clusters are treated as region landmarks. Edge segments are scored by how many of the region proposals terminate at the edge. These two types of landmarks are detected on every image (figure \ref{fig:topLandmarks}), and are matched between nearby images based on texture and shape (figure \ref{fig:matching}). Details of this method can be found in our earlier paper. All the matchings then form a graph where each detection is a node and each matching is an edge. Node groups that consist of overlapping large cliques are deemed to correspond to robust landmarks (figure \ref{fig:robustLMandMatchingGraph}). We have found several limitations to this method. Particularly, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%First, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%Second, candidate landmarks are fixed prior to the matching. It is necessary to be able to correct wrong detections, based on global cues. It is desirable to perform detection and matching iteratively. 
%We are currently developing a new method.
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/top_landmarks.png}
%	\caption{Top landmarks found by our previous method}
%	\label{fig:topLandmarks}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/matching.png}
%	\caption{Example of matching by our previous method}
%	\label{fig:matching}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/robustLandmark2.png}
%	\includegraphics[width=\textwidth]{../figures/matchingGraph2.png}
%	\caption{Example of a consistent landmark found by our previous method and its corresponding group in the matching graph}
%	\label{fig:robustLMandMatchingGraph}
%\end{figure}
%
%Our system updates landmark models based on both detections made by itself and corrections provided by human experts. Learning from human corrections involves 1) learning to incorporate the variability of landmark appearances, e.g. by using more prototypes, and 2) learning to separate ambiguous landmarks, e.g. by building classifiers.


%\section{Preliminary Results}


\bibliography{bibfile}
\bibliographystyle{splncs03}


\end{document}
