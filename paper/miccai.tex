\documentclass{llncs}

\usepackage{makeidx}  % allows for indexgeneration

\usepackage{graphics, graphicx, xcolor}
\usepackage{amsmath}
%\usepackage[square]{natbib}
\usepackage{cite}
\usepackage[hidelinks, colorlinks, linkcolor={red},citecolor={blue}, urlcolor={blue}, backref=section]{hyperref}

\usepackage{times}
\usepackage{mathptmx}
%\usepackage{newtxtext,newtxmath}

\newcommand{\authcmt}[2]{\textcolor{#1}{#2}}
\newcommand{\yuncong}[1]{\authcmt{red}{[YC: #1]}}
\newcommand{\yoav}[1]{\authcmt{blue}{[YF: #1]}}

\begin{document}

%\abovedisplayskip=2pt
%\abovedisplayshortskip=1pt
%\belowdisplayskip=2pt 
%\belowdisplayshortskip=1pt
\textfloatsep=5pt
\intextsep=3pt

%
%\mainmatter              % start of the contributions
%
\title{Building an Active Atlas for the Mouse Brain}
%
%\titlerunning{Robust Landmark Detection for Mouse Brain Images}  % abbreviated title (for running head)
%%                                     also used for the TOC unless
%%                                     \toctitle is used
%%
\author{Yuncong Chen\inst{1},  Partha Mitra, Harvey
  Karten\inst{2}, David Kleinfeld\inst{2}, Yoav Freund\inst{1}}
%
%\authorrunning{Yuncong Chen et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
% \tocauthor{Yuncong Chen, Yoav Freund}
%
\institute{UCSD Computer Science and Engineering Department
\and UCSD Physics Department}

\maketitle              % typeset the title of the contribution
\begin{abstract}

We propose a semi-supervised system for generating a reference atlas from histology image series of the mouse brainstem.
The atlas contains the mean and variance of the positions and shapes of nine anatomical landmarks. By learning landmark classifiers, the system registers new data to the atlas. Registered data further improve the generalizability of the classifiers.

\keywords{landmark detection, atlas generation, mouse brain, registration, automated annotation}

\end{abstract}

\section{Overview}

One of the most important tools to neuroscientists, the brain atlas
provides a standard model for the anatomy of a certain species'
brain. It helps one identify the location of anatomical structures in a new sample. It also allows one to map different samples to a common coordinate system, so that one can quantify the spatial variance of a particular structure between individuals, or correlate gene expression patterns spatially to identify neural circuitry.

In this paper we focus on building an atlas for the mouse brainstem
using light microscopy stained with Nissl.
Existing mouse brain atlases, such as the Paxinos'
\cite{paxinos2004mouse}, Waxholm Space \cite{johnson2010waxholm} and
the Allen Reference Atlas \cite{dong2008allen}, have some
limitations. 
\yoav{In american technical prose, you start with the most significant
  difference and follow it with the less important ones. I think that the manual work and the
  lack of registration tools are the most significant
  differences. Then the variance, and then the specific problem with
  the brain-stem having less grey-level variation.}
First, they do not have the desired level of details in
the brainstem. Second, they are merely visual references. There are no
tools for registering new data to the atlas. Third, they are hard to
update and refine as new data is collected. Fourth, they do not
charactarize the variation in the location and shape of structures. Lastly, a lot of manual work is involved in specifying registration landmarks and making annotations.

We propose a new type of atlas which we call an ``active atlas''. On the one hand, an active atlas is an anatomical reference model. It contains the mean and variance of position and shape of major anatomical structures. On the other hand, an active atlas includes landmark detectors. These detectors are texture classifiers trained in a semi-supervised fashion to detect regions with salient texture, such as nuclei and tracts, that can serve as registration landmarks. Such an atlas is ``active" because the detectors allows our system to actively detect landmarks on new data for registeration, instead of being a ``passive" registration template; and also because these detectors can update themselves from new data, thus not ``static".

This paper proposes a machine-learning based method for developing an active atlas, based on image series of Nissl-stained cryo-sectioned brains.

The rest of the paper is organized as follows. In Section~\ref{sec:related} we
describe related work. In Section 3 we describe the semi-supervised
method we used to create landmark detectors. In section 4 we describe
the alignment algorithm and the way in which we quantify the variation
in the location of the landmarks. In section 5 we describe out
experimental result. We conclude in section 6 with lessons learned and
future plans.


%\yuncong{Putting MRI at the very first word of the paper makes me feel this paper is about MRI. Also we are not really comparing against MRI, the related work we compare to mostly use confocal or two-photon microscopy, which produce volumetric images. The advantage of MRI is the preservation of a realistic 3D volume, which can be obtained by confocal / two-photon microscopy as well and at a much higher resolution. So I think unless we compare with these techniques, we better not do it. What we can discuss as a motivation is why some neuroscientists prefer to actually cut and image the sections, instead of imaging the whole volume using optical sectioning. In fact, Allen did use serial two-photon microscopy stacks for their connectivity atlas work. So I guess tissue thickness is not the reason? Maybe David can answer this.. }

%MRI has gained great popularity in recent years, however, the
%limitations of MRI in terms of resolution and variety of markers
%(stains) means that light microscopy is still a method of great
%importance.  One of the most important tools when analyzing light
%microscopy brain section is the brain atlas. Over time Atlases have
%improved in accuracy and coverage: Starting with Paxinos, and the
%Waxholm Space \cite{johnson2010waxholm}, and continuing with the Allen
%Reference Atlas \cite{dong2008allen} and its successors.
%
%An atlas is a visual reference: the researcher compares the
%images in the atlas to new section images in order to orient herself
%and to find the loci of interest. This is a time consuming
%process. The fact that the researcher is interested only in a specific
%set of loci means that other parts of the brain will not be
%identified. 
%
%We propose a new type of atlas which we call the ``active
%atlas''. Unlike ``static atlases'', which are used as
%visual reference, the active atlas is a computer program that takes a
%section stack as input and then overlays a standard brain coordinate
%system (the Waxholm space coordinates) on the sections.
%
%%\yuncong{I do not have results for a standard coordinate system yet. Harvey was suggesting to use the stereotactic coordinate system in Paxinos. And in the future, align the stereotactic system to Walxhom space as well as Allen Reference Brain's coordinate system. I have not done these yet. Do you think I should at least specify a stereotactic coordinate system, so that we can show images with grid lines on top of them ? }
%
%An active atlas represents both the nominal location of the brain loci
%and the variation in these locations.
%
%An active atlas will enable automatic analysis of specific
%stains (dyes?). Dyes are available that can identfy highly
%specific characteristics in the brain. RNA binding markers can
%identify gene activity, forward projecting and backward projecting
%dyes mark the connectivity between brain regions and muscles and
%between brain regions and sensors. \yoav{David please help!}
%
%The active atlas is related to the common practice of
%section-to-section registration, but is fundamentally different.
%\begin{itemize}
%\item Registration aligns two neighboring sections of the same brain to each other,
%  while the active atlas aligns a section to a plane in the atlas.
%\item Registration is intended to produce a 3D image from a single
%  stack, the active atlas is intended to align multiple brains to each other.
%\end{itemize}
%
%%\yuncong{These two fundamental differences simply are the differences between 2D-2D registration and 3D-3D registration. They are not unique to the ``active atlas" concept. I don't think this part is necessary. Otherwise, we should emphasize how our approach for 3D-3D registration is different from other projects, most of whom rely on intensity correlation, contour consistency, or picking 3D point rather than region landmarks.}
%
%\noindent Some challanges on the way to producing an atlas are:
%\begin{itemize}
%\item Grey level information can only identify some of the landmarks
%  in a typical section. Much of the area is of similar average grey
%  level. Important information lies in the shapes and organization of
%  the neurons.
%\item When comparing the same locus in different brains, there is no
%  one-to-one mapping between the neurons. The organization of the
%  neurons can only be characterized using statistical properties.
%\end{itemize}
%
%%\yuncong{I feel this part involves a mix of issues/claims, some of which apply to all registration method (e.g. grey-level is not enough, the need to describe texture), some of which apply to any atlas generation method (e.g. 3D-3D registration), and some of which apply only to ACTIVE atlas (still weak - what separates ``active atlas" from an ``static atlas" plus a 3D-3D registration algorithm).}
%
%
%
%Our contribution is in developing a methodology for developing an \yuncong{active}
%atlas and an alignment algorithm for matching a new stack to this
%atlas. 
%
%\yuncong{I think we should give a high-level description of our methodology here.}
%
%The rest of the paper is organized as follow. In Section~\ref{sec:related} we
%describe related work. In Section 3 we describe the semi-supervised
%method we used to create landmark detectors. In section 4 we describe
%the alignment algorithm and the way in which we quantify the variation
%in the location of the landmarks. In section 5 we describe out
%experimental result. We conclude in section 6 with lessons learned and
%future plans. 

\section{Related work}
\label{sec:related}

Existing atlases of the mouse brain include Paxinos, Waxholm Space \cite{johnson2010waxholm}, and the more recent Allen Reference Atlas \cite{dong2008allen} and its successors, on top of which gene expression data \cite{lein2007genome, ng2009anatomic} as well as connectivity information \cite{oh2014mesoscale} are mapped. The latest version of their common coordinate framework \cite{ccf2015} is generated by deformably averaging two-photon microscopy images and manually demarcating structures with the help of immunohistochemistry data and genetic labeling data. Atlases for smaller organisms such as fruit flies \cite{peng2011brainaligner, chiang2011three} and zebrafish \cite{ronneberger2012vibe, randlett2015whole} are mostly based on volumetric images acquired by confocal microscopy. 
For registration, the BrainAligner program \cite{peng2011brainaligner} relies on matching high-curvature points, and the ViBE-Z project \cite{ronneberger2012vibe} used trained classifiers to detect predefined 3D landmarks. 

%\yuncong{Do you think the two paragraphs below should be in the first section, since they highlight the largest feature of our system (i.e. use machine learning), and provides more reasons why it is ``active" }



\section{Methodology}

\subsection{Learning Texture Classifiers using Convolutional Neural Network}

%Unlike cerebrum and cerebellum, brainstem does not have striations. Grey-level information alone is not sufficient to discern most of the nuclei. Region textures are essential.

To bootstrap the atlas generation process, we picked an arbitrary stack, and asked an expert anatomist to annotate every other image for major landmarks by drawing polygons on the images using a homemade program (Figure 1). The results are 100 polygons for 19 different landmarks that span the entire brainstem, including nuclei (e.g. facial motor nucleus, trigeminal nucleus) and fiber tracts (e.g. trigeminal spinal tract, superior cerebellar peduncle). Patches of size 224-by-224 that are completely inside of each annotation polygon are extracted. Random patches from outside of any polygon are also extracted as patches for ``background". These patches form the training set for the texture classifier. 
A multiway classifier is obtained by fine-tuning the inception-BN network [1] using the training set. For an input patch, the classifier outputs a 20-dimensional probability vector, indicating the probability that the patch belongs to either the background or each of the 19 landmarks.

The classifier is applied to images in all other stacks. To save computation, instead of predicting for patches centered at every pixel, the classifier predicts at grid points with a spacing of 56. The area between grid points is interpolated using bivariate spline. The result is a probability map for each image, where each pixel is assigned a probability vector.

\subsection{Intra-stack Registration}

As the brain sections are prepared using an advanced tape-transfer system, which almost perfectly preserves the shape of the sections, 3-parameter rigid transforms are sufficient to bring all sections into reasonable alignment. The transformations are found using the \textit{elastix} program \cite{klein2010elastix}, based on maximizing the normalized correlation of the intensity between the thumbnail versions of the sections. 

Once the registration transformations are known, a probability volume is reconstructed for each stack from the probability maps of all its sections.  In a probability volume, each voxel has a probability vector. For the annotated stack, an annotation volume is reconstructed, in which each voxel has a scalar label. To facilitate registration at the next stage, the 3D contours of annotations are smoothed. We assume the sections all have constant thickness and are parallel to other sections in the same stack.

\subsection{3D-3D Registration}

To generate the atlas, we need to register the reconstructed volumes of all individuals in 3D and obtain an average. 
This process is done iteratively. We begin by using the annotated volume as the template and register the other volumes to it. Because the sections may be cut at different angles for different stacks, in effect resulting in shears between the volumes, we find 12-parameter 3D affine transformations.

Given the annotated volume $\Omega$ and a probability volume $S$, the best transformation is one that maximizes the ``same-class overlap" objective:

\[ M(T) = \sum_k \sum_{p \in \Omega_k} S_k[Tp]\;,\]
%\[ M(T) = \sum_{p \in \Omega} S_k(Tp) \cdot 1[\Omega(p) = k] \;,\]\\
where $T$ is a 3-by-4 affine transform matrix, $\Omega_k$ is the set of voxels in the annotation volume that have label $k$, $S_k$ is the volume formed by taking the entries corresponding to class $k$ from the probability vectors of every voxel in $S$.

The optimization starts with grid search over the 3 translation parameters. Then gradient descent with Adagrad is used to approach the optimum.

\subsection{Localizing Landmarks on Registered Images} 

To compute the statistics of landmarks' position and shape, we need to accurately localize the landmarks of the registered volumes in 3D.

The fact that the probability volumes are registered to the annotation volume means the annotations can be propagated to these volumes. Figure 1 shows the contours of projected annotations on one of the registered images. These projected annotation contours provide an initial guess for the landmark positions on the images. Starting from them, morphological snake \cite{marquez2014morphological} is used to fit the probability map of each landmark, giving more accurate contours.



%An $M$-way classifier detects landmarks on each image, assigning a probability vector to each pixel. Intra-stack registration is performed for each stack separately based on intensity. Assuming constant section thickness and the sections being parallel, a volume can be reconstructed for each stack, in which every voxel has a probability vector.
%
%Given a stack of section images, the \textit{elastix} program \cite{klein2010elastix} is used to find rigid transformations that align every pair of consecutive sections, by maximizing the normalized correlation of image intensity. These transformations are then composed, bringing the whole stack into a rough alignment. Because the tape-transfer system used to process these sections preserves the tissues very well, 3-parameter rigid transforms are sufficient for this stage of registration.
%
%For each image in the stack, a $M$-way classifier assigns a landmark probability vector to each pixel. The result is a set of score maps ${S_l}$, one for each landmark.
%
%We then register the test volume to the atlas. A 3D rigid transform is seeked that maximizes the same-class overlap score between the test volume and the atlas. The score is defined as:
%\[ M(T) = \sum_l \sum_{p \in V_l} S_l[T(p)]\;,\]
%where $T$ is the transformation that maps voxels from the atlas to the test volume, $l$ indexes the landmark labels, $V_l$ is the set of voxels in the atlas with label $l$, $S_l$ is the score map for label $l$.
%
%The optimal parameters are found using a coarse-to-fine grid search, followed by gradient descent that moves the solution towards the maxima.

%Three components of the system employ machine learning: landmark discovery, landmark modelling and landmark localization. 
%
%%They allow regions of interest to be detected on the images with little supervision.
%
%Landmark discovery involves finding candidate landmarks that are salient and consistent along the stack. Each landmark is modelled using their appearance features such as texture, shape and striation directions, in addition to position. On every image, the landmarks are localized based on their models. Models are also updated according to detections at the new location. In a sentence, learning in this system is a semi-supervised, interactive and iterative scheme that combines unsupervised model discovery with examples (corrections) from human experts.
%
%
%Previously we have developed a superpixel-based method that identifies salient and consistent regions and boundaries across an image stack. In that method, region growing is used to obtain a region proposal for each superpixel. These region proposals are clustered and weighted according to saliency. Salient clusters are treated as region landmarks. Edge segments are scored by how many of the region proposals terminate at the edge. These two types of landmarks are detected on every image (figure \ref{fig:topLandmarks}), and are matched between nearby images based on texture and shape (figure \ref{fig:matching}). Details of this method can be found in our earlier paper. All the matchings then form a graph where each detection is a node and each matching is an edge. Node groups that consist of overlapping large cliques are deemed to correspond to robust landmarks (figure \ref{fig:robustLMandMatchingGraph}). We have found several limitations to this method. Particularly, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%First, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%Second, candidate landmarks are fixed prior to the matching. It is necessary to be able to correct wrong detections, based on global cues. It is desirable to perform detection and matching iteratively. 
%We are currently developing a new method.
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/top_landmarks.png}
%	\caption{Top landmarks found by our previous method}
%	\label{fig:topLandmarks}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/matching.png}
%	\caption{Example of matching by our previous method}
%	\label{fig:matching}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/robustLandmark2.png}
%	\includegraphics[width=\textwidth]{../figures/matchingGraph2.png}
%	\caption{Example of a consistent landmark found by our previous method and its corresponding group in the matching graph}
%	\label{fig:robustLMandMatchingGraph}
%\end{figure}
%
%Our system updates landmark models based on both detections made by itself and corrections provided by human experts. Learning from human corrections involves 1) learning to incorporate the variability of landmark appearances, e.g. by using more prototypes, and 2) learning to separate ambiguous landmarks, e.g. by building classifiers.


%\section{Preliminary Results}


\bibliography{bibfile}
\bibliographystyle{splncs03}


\end{document}
