\documentclass{llncs}

\usepackage{makeidx}  % allows for indexgeneration

\usepackage{graphics, graphicx, xcolor}
\usepackage{amsmath}
%\usepackage[square]{natbib}
\usepackage{cite}
\usepackage[hidelinks, colorlinks, linkcolor={red},citecolor={blue}, urlcolor={blue}, backref=section]{hyperref}

\usepackage{times}
\usepackage{mathptmx}
%\usepackage{newtxtext,newtxmath}

%\newcommand{\authcmt}[2]{\textcolor{#1}{#2}}
%\newcommand{\yuncong}[1]{\authcmt{red}{[YC: #1]}}
%\newcommand{\yoav}[1]{\authcmt{blue}{[YF: #1]}}

\begin{document}

%\abovedisplayskip=2pt
%\abovedisplayshortskip=1pt
%\belowdisplayskip=2pt 
%\belowdisplayshortskip=1pt
\textfloatsep=5pt
\intextsep=3pt

%
%\mainmatter              % start of the contributions
%
\title{Building Active Atlas for Mouse Brainstem}
%
%\titlerunning{Robust Landmark Detection for Mouse Brain Images}  % abbreviated title (for running head)
%%                                     also used for the TOC unless
%%                                     \toctitle is used
%%
\author{Yuncong Chen\inst{1}, Yoav Freund\inst{1}, David Kleinfeld\inst{2}}
%
%\authorrunning{Yuncong Chen et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
% \tocauthor{Yuncong Chen, Yoav Freund}
%
\institute{UCSD Computer Science and Engineering Department
\and UCSD Physics Department}

\maketitle              % typeset the title of the contribution
\begin{abstract}

We propose a semi-supervised system for generating a reference atlas from histology image series of the mouse brainstem.
The atlas contains the mean and variance of the positions and shapes of nine anatomical landmarks. By learning landmark classifiers, the system registers new data to the atlas. Registered data further improve the generalizability of the classifiers.

\keywords{landmark detection, atlas generation, mouse brain, registration, automated annotation}

\end{abstract}

\section{Overview}

With the advance of genetic labeling and high-throughput imaging techniques, there is an increasing need for brain atlases that characterize gene expression by statistical summarization of information in a large number of subjects.

The common workflow for building an atlas is to first generate an anatomical reference model by ``averaging" many brains and then register the gene expression patterns to this model. 

This allows one to computationally quantify the variance between individuals, and allows one to identify the anatomical identities of regions of certain gene expressions.


%The difference between brains comes from two sources. One is physical deformation resulted from processing and the other is inherent biological variation. We assume that physical deformations are characterized by rigid transforms with scaling. Registering test brains to the atlas eliminates these deformtions. Any residual difference is then regarded as biological variations, which is of interest to neuroscientists.
%
%The atlas contains a set of landmark detectors. They detect regions and boundaries that are salient on the images.
%
%Each detector is based on 1) Texture
%2) Geometry: volume in 3D common coordinate system. The volume is represented by a probabilistic model such as deformable template. This allows for registration based on shape at different levels of details, by considering different number of top principle components.
%
%
%
%The registration to atlas and landmark detection are performed iteratively, from coarse to fine resolution.
%
%
%Human annotation is optional. 
%
%An anatomist can annotate any region that is of interest by drawing contours on an image.
%
%To take advantage of new images, it should be easy to train the classifiers in an incremental way.
%Since new landmarks are expected be introduced, the classification framework should be flexible regarding adding new classes.
%
%
%In addition to acting as a reference volume, the system 
%
%Based on the fact that the system does not top-down detection by classifying and the detectors evolve given more images,
%
%
%
%Our atlas is designed with the goal of facilitating the registration of data from different labs. Detectors are associated with each landmark, and can be updated based on new data.
%
%
%we call our system an "active atlas".
%in comparison to existing atlases


Existing atlases of the mouse brain include Paxinos, Waxholm Space \cite{johnson2010waxholm}, and the more recent Allen Reference Atlas \cite{dong2008allen} and its successors, on top of which gene expression data \cite{lein2007genome, ng2009anatomic} as well as connectivity information \cite{oh2014mesoscale} are mapped. The latest version of their common coordinate framework \cite{ccf2015} is generated by deformably averaging two-photon microscopy images and manually demarcating structures with the help of immunohistochemistry data and genetic labeling data. Atlases for smaller organisms such as fruit flies \cite{peng2011brainaligner, chiang2011three} and zebrafish \cite{ronneberger2012vibe, randlett2015whole} are mostly based on volumetric images acquired by confocal microscopy. 
For registration, the BrainAligner program \cite{peng2011brainaligner} relies on matching high-curvature points, and the ViBE-Z project \cite{ronneberger2012vibe} used trained classifiers to detect predefined 3D landmarks. 

These atlases are not updateable from new data, and do not provide means that facilitate the registration of new data.

This paper proposes a machine-learning based method that generates an anatomical reference model from Nissl-stained cryo-section images. 

In addition to describing the statistics of position and shape of anatomical structures, the model also include landmark detectors. These detectors are texture classifiers trained in a semi-supervised fashion to detect regions with salient texture that can serve as registration landmarks, such as nuclei and tracts. Because these detectors allows our system to actively detect landmarks on new data for registeration, instead of being a mere registration template; and also because these detectors can update themselves from new data, we refer to this system as an ``active atlas". 


\section{Methodology}


Registration to the atlas is based on landmark probability maps generated by the classifiers.


An $M$-way classifier detects landmarks on each image, assigning a probability vector to each pixel. Intra-stack registration is performed for each stack separately based on intensity. Assuming constant section thickness and the sections being parallel, a volume can be reconstructed for each stack, in which every voxel has a probability vector.

Given a stack of section images, the \textit{elastix} program \cite{klein2010elastix} is used to find rigid transformations that align every pair of consecutive sections, by maximizing the normalized correlation of image intensity. These transformations are then composed, bringing the whole stack into a rough alignment. Because the tape-transfer system used to process these sections preserves the tissues very well, 3-parameter rigid transforms are sufficient for this stage of registration.

For each image in the stack, a $M$-way classifier assigns a landmark probability vector to each pixel. The result is a set of score maps ${S_l}$, one for each landmark.

We then register the test volume to the atlas. A 3D rigid transform is seeked that maximizes the same-class overlap score between the test volume and the atlas. The score is defined as:
\[ M(T) = \sum_l \sum_{p \in V_l} S_l[T(p)]\;,\]
where $T$ is the transformation that maps voxels from the atlas to the test volume, $l$ indexes the landmark labels, $V_l$ is the set of voxels in the atlas with label $l$, $S_l$ is the score map for label $l$.

The optimal parameters are found using a coarse-to-fine grid search, followed by gradient descent that moves the solution towards the maxima.

%Three components of the system employ machine learning: landmark discovery, landmark modelling and landmark localization. 
%
%%They allow regions of interest to be detected on the images with little supervision.
%
%Landmark discovery involves finding candidate landmarks that are salient and consistent along the stack. Each landmark is modelled using their appearance features such as texture, shape and striation directions, in addition to position. On every image, the landmarks are localized based on their models. Models are also updated according to detections at the new location. In a sentence, learning in this system is a semi-supervised, interactive and iterative scheme that combines unsupervised model discovery with examples (corrections) from human experts.
%
%
%Previously we have developed a superpixel-based method that identifies salient and consistent regions and boundaries across an image stack. In that method, region growing is used to obtain a region proposal for each superpixel. These region proposals are clustered and weighted according to saliency. Salient clusters are treated as region landmarks. Edge segments are scored by how many of the region proposals terminate at the edge. These two types of landmarks are detected on every image (figure \ref{fig:topLandmarks}), and are matched between nearby images based on texture and shape (figure \ref{fig:matching}). Details of this method can be found in our earlier paper. All the matchings then form a graph where each detection is a node and each matching is an edge. Node groups that consist of overlapping large cliques are deemed to correspond to robust landmarks (figure \ref{fig:robustLMandMatchingGraph}). We have found several limitations to this method. Particularly, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%First, the shapes of landmarks need to be described by either sets of superpixels or their edges, which are not flexible enough for an atlas. 
%%Second, candidate landmarks are fixed prior to the matching. It is necessary to be able to correct wrong detections, based on global cues. It is desirable to perform detection and matching iteratively. 
%We are currently developing a new method.
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/top_landmarks.png}
%	\caption{Top landmarks found by our previous method}
%	\label{fig:topLandmarks}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/matching.png}
%	\caption{Example of matching by our previous method}
%	\label{fig:matching}
%\end{figure}
%
%\begin{figure}
%\centering
%	\includegraphics[width=\textwidth]{../figures/robustLandmark2.png}
%	\includegraphics[width=\textwidth]{../figures/matchingGraph2.png}
%	\caption{Example of a consistent landmark found by our previous method and its corresponding group in the matching graph}
%	\label{fig:robustLMandMatchingGraph}
%\end{figure}
%
%Our system updates landmark models based on both detections made by itself and corrections provided by human experts. Learning from human corrections involves 1) learning to incorporate the variability of landmark appearances, e.g. by using more prototypes, and 2) learning to separate ambiguous landmarks, e.g. by building classifiers.


%\section{Preliminary Results}


\bibliography{bibfile}
\bibliographystyle{splncs03}


\end{document}
